{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and restore models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model progress can be saved during — and after — training. It is good practice to share:\n",
    "* code to create a model\n",
    "* the trained weights and parameters\n",
    "\n",
    "How to save a model depends on the API used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the simple and well-known dataset MNIST is used, since the goal is to explore the saving and restoring mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0 # -1 infers the shape => 1000 in this case (nb of examples)\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses sparse categorical crosentropy, because the target labels are integers. If we used categorical crossentropy we would need to encode them with one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Returns a short sequential model\n",
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.keras.activations.relu, input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "  ])\n",
    "  \n",
    "  model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save checkpoints during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary use case is to automatically save checkpoints during and at the end of training. This way we can use a trained model without having to retrain it, or pick-up training where you left of—in case the training process was interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 1.1548 - acc: 0.6833\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A09A90EB8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 922us/sample - loss: 1.1396 - acc: 0.6850 - val_loss: 0.6710 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      " 928/1000 [==========================>...] - ETA: 0s - loss: 0.4208 - acc: 0.8761\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A09A90EB8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.4182 - acc: 0.8780 - val_loss: 0.5596 - val_acc: 0.8210\n",
      "Epoch 3/10\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 0.2737 - acc: 0.9345\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A09A90EB8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 652us/sample - loss: 0.2808 - acc: 0.9330 - val_loss: 0.4468 - val_acc: 0.8590\n",
      "Epoch 4/10\n",
      " 896/1000 [=========================>....] - ETA: 0s - loss: 0.2007 - acc: 0.9565\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A09A90EB8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 608us/sample - loss: 0.2093 - acc: 0.9530 - val_loss: 0.4372 - val_acc: 0.8610\n",
      "Epoch 5/10\n",
      " 864/1000 [========================>.....] - ETA: 0s - loss: 0.1527 - acc: 0.9641\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A09A90EB8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 542us/sample - loss: 0.1564 - acc: 0.9610 - val_loss: 0.4062 - val_acc: 0.8690\n",
      "Epoch 6/10\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.1175 - acc: 0.9760\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A09A90EB8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.1171 - acc: 0.9770 - val_loss: 0.4159 - val_acc: 0.8680\n",
      "Epoch 7/10\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0806 - acc: 0.9917\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A09A90EB8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.0807 - acc: 0.9920 - val_loss: 0.4018 - val_acc: 0.8660\n",
      "Epoch 8/10\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0624 - acc: 0.9917\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A09A90EB8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.0615 - acc: 0.9920 - val_loss: 0.4067 - val_acc: 0.8690\n",
      "Epoch 9/10\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0470 - acc: 0.9979\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A09A90EB8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.0493 - acc: 0.9970 - val_loss: 0.4129 - val_acc: 0.8700\n",
      "Epoch 10/10\n",
      " 864/1000 [========================>.....] - ETA: 0s - loss: 0.0380 - acc: 0.9988\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A09A90EB8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 576us/sample - loss: 0.0381 - acc: 0.9990 - val_loss: 0.3890 - val_acc: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19a09fc6c50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels,  epochs = 10, \n",
    "          validation_data = (test_images,test_labels),\n",
    "          callbacks = [cp_callback])  # pass callback to training\n",
    "\n",
    "# This may generate warnings related to saving the state of the optimizer.\n",
    "# These warnings (and similar warnings throughout this notebook)\n",
    "# are in place to discourage outdated usage, and can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 88us/sample - loss: 2.3514 - acc: 0.0650\n",
      "Untrained model, accuracy:  6.50%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By loading from the checkpoint, we can see it is indeed the same model trained before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.4100 - acc: 0.8650\n",
      "Restored model, accuracy: 86.50%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "loss,acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A7E70FCC0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A7E70FCC0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A7E70FCC0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A7E70FCC0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A7E70FCC0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A7E70FCC0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A7E70FCC0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A7E70FCC0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A7E70FCC0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A7E70FCC0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00050: saving model to training_2/cp-0050.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A7E70FCC0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19a7f216be0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include the epoch in the file name. (uses `str.format`)\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    # Save weights, every 5-epochs.\n",
    "    period=5)\n",
    "\n",
    "model = create_model()\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs = 50, callbacks = [cp_callback],\n",
    "          validation_data = (test_images,test_labels),\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is DATA\n",
      " Volume Serial Number is 881A-0976\n",
      "\n",
      " Directory of D:\\Projetos\\DeepLearning_MiniProjects\\MNIST_SaveRestoreModels\\training_2\n",
      "\n",
      "12/06/2019  18:02    <DIR>          .\n",
      "12/06/2019  18:02    <DIR>          ..\n",
      "12/06/2019  18:02                81 checkpoint\n",
      "12/06/2019  18:02         1ÿ631ÿ508 cp-0000.ckpt.data-00000-of-00001\n",
      "12/06/2019  18:02               648 cp-0000.ckpt.index\n",
      "12/06/2019  18:02         1ÿ631ÿ508 cp-0005.ckpt.data-00000-of-00001\n",
      "12/06/2019  18:02               648 cp-0005.ckpt.index\n",
      "12/06/2019  18:02         1ÿ631ÿ508 cp-0010.ckpt.data-00000-of-00001\n",
      "12/06/2019  18:02               648 cp-0010.ckpt.index\n",
      "12/06/2019  18:02         1ÿ631ÿ508 cp-0015.ckpt.data-00000-of-00001\n",
      "12/06/2019  18:02               648 cp-0015.ckpt.index\n",
      "12/06/2019  18:02         1ÿ631ÿ508 cp-0020.ckpt.data-00000-of-00001\n",
      "12/06/2019  18:02               648 cp-0020.ckpt.index\n",
      "12/06/2019  18:02         1ÿ631ÿ508 cp-0025.ckpt.data-00000-of-00001\n",
      "12/06/2019  18:02               648 cp-0025.ckpt.index\n",
      "12/06/2019  18:02         1ÿ631ÿ508 cp-0030.ckpt.data-00000-of-00001\n",
      "12/06/2019  18:02               648 cp-0030.ckpt.index\n",
      "12/06/2019  18:02         1ÿ631ÿ508 cp-0035.ckpt.data-00000-of-00001\n",
      "12/06/2019  18:02               648 cp-0035.ckpt.index\n",
      "12/06/2019  18:02         1ÿ631ÿ508 cp-0040.ckpt.data-00000-of-00001\n",
      "12/06/2019  18:02               648 cp-0040.ckpt.index\n",
      "12/06/2019  18:02         1ÿ631ÿ508 cp-0045.ckpt.data-00000-of-00001\n",
      "12/06/2019  18:02               648 cp-0045.ckpt.index\n",
      "12/06/2019  18:02         1ÿ631ÿ508 cp-0050.ckpt.data-00000-of-00001\n",
      "12/06/2019  18:02               648 cp-0050.ckpt.index\n",
      "              23 File(s)     17ÿ953ÿ797 bytes\n",
      "               2 Dir(s)  667ÿ718ÿ631ÿ424 bytes free\n"
     ]
    }
   ],
   "source": [
    "! dir {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2\\\\cp-0050.ckpt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4760 - acc: 0.8730\n",
      "Restored model, accuracy: 87.30%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights(latest)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually save weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A7F25F3C8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.4760 - acc: 0.8730\n",
      "Restored model, accuracy: 87.30%\n"
     ]
    }
   ],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Restore the weights\n",
    "model = create_model()\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "loss,acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Save the entire model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire model can be saved to a file that contains:\n",
    "* the weight values\n",
    "* the model's configuration\n",
    "* the optimizer's configuration (depends on set up). \n",
    "\n",
    "This allows you to checkpoint a model and resume training later—from the exact same state—without access to the original code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving a fully-functional model is very useful—you can load them in TensorFlow.js (HDF5, Saved Model) and then train and run them in web browsers, or convert them to run on mobile devices using TensorFlow Lite (HDF5, Saved Model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 451us/sample - loss: 1.0890 - acc: 0.6980\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 305us/sample - loss: 0.4127 - acc: 0.8890\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 319us/sample - loss: 0.2822 - acc: 0.9240\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 308us/sample - loss: 0.2002 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 294us/sample - loss: 0.1470 - acc: 0.9720\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including weights and optimizer.\n",
    "new_model = keras.models.load_model('my_model.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.4141 - acc: 0.8730\n",
      "Restored model, accuracy: 87.30%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, it is not able to save TensorFlow optimizers (from tf.train)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 659us/sample - loss: 1.1400 - acc: 0.6720\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 486us/sample - loss: 0.4206 - acc: 0.8790\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 434us/sample - loss: 0.2691 - acc: 0.9310\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 429us/sample - loss: 0.1963 - acc: 0.9590\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 495us/sample - loss: 0.1475 - acc: 0.9660\n",
      "1000/1000 [==============================] - 0s 189us/sample - loss: 0.4103 - acc: 0.8660\n",
      "Restored model, accuracy: 86.60%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000019A0B8B7A58>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:Model was compiled with an optimizer, but the optimizer is not from `tf.train` (e.g. `tf.train.AdagradOptimizer`). Only the serving graph was exported. The train and evaluate graphs were not added to the SavedModel.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./saved_models\\1560361247\\saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = tf.contrib.saved_model.save_keras_model(model, \"./saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.contrib.saved_model.load_keras_model(saved_model_path)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 202us/sample - loss: 0.4103 - acc: 0.8660\n",
      "Restored model, accuracy: 86.60%\n"
     ]
    }
   ],
   "source": [
    "# The model has to be compiled before evaluating.\n",
    "# This step is not required if the saved model is only being deployed.\n",
    "\n",
    "new_model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Evaluate the restored model.\n",
    "loss, acc = new_model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
